{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f8da59-5390-4560-99f2-f5bbe78a5c2d",
   "metadata": {},
   "source": [
    "# Comparing M6A ML models (HIFI read models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649d8db4-25a5-487d-bf74-a8b644215672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the requisite imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import xgboost as xgb \n",
    "from m6a_calling import M6ANet\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             balanced_accuracy_score,\n",
    "                             matthews_corrcoef,\n",
    "                             roc_auc_score,\n",
    "                             average_precision_score,\n",
    "                             roc_curve,\n",
    "                             precision_recall_curve\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c940b-1995-4353-8cf7-e13cce06da17",
   "metadata": {},
   "source": [
    "### Read in the HiFi test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b66ab53-6523-411a-b7be-5bc46911cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HiFi data\n",
    "\n",
    "data_path = \"../data/deprecated-data-2022-10-19/m6A_test_other_half_hifi.npz\"\n",
    "\n",
    "train_val_data = np.load(data_path, allow_pickle=True)\n",
    "\n",
    "# Get the dictionary from the containing relevant data\n",
    "train_val_data = train_val_data['save_data_dict'][()]\n",
    "\n",
    "# Load test features and labels\n",
    "X_test = train_val_data['X_test']\n",
    "y_test = train_val_data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e870df-0828-40b2-a2ef-c1783ff94c69",
   "metadata": {},
   "source": [
    "### Predict using the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a47e2b-7d85-4ce0-b75f-235dc1fdd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_other_half_hifi.3.best.torch\", map_location=torch.device('cpu'))\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "test_pred_cnn = m6a_model.predict(X_test, device='cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b18063-fbdd-4570-b182-e418a375278a",
   "metadata": {},
   "source": [
    "### Predict using the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b474c21-3345-48fb-ba31-f0dad569c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst2 = xgb.Booster({'nthread': 4})  # init model\n",
    "bst2.load_model('models/xgboost.otherhalf.hifi.100rds.json')  # load data\n",
    "\n",
    "X_test_2d = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "\n",
    "dtest = xgb.DMatrix(X_test_2d)\n",
    "test_pred_xgb = bst2.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5f3ab-d132-44ff-bc52-1b5a1170a0cb",
   "metadata": {},
   "source": [
    "### Plot ROC curve for XGBoost and CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c892a1d-42cf-480d-a57e-ae6cc2fcd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.axline([0,0], slope=1, c=\"black\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[:, 0], test_pred_cnn[:, 0], pos_label=1)\n",
    "print(f\"AUC-ROC CNN: {metrics.auc(fpr, tpr):.03f}\")\n",
    "plt.plot(fpr, tpr, c='gray', label=f\"CNN-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[:, 0], test_pred_xgb, pos_label=1)\n",
    "print(f\"AUC-ROC XGBoost: {metrics.auc(fpr, tpr):.03f}\")\n",
    "plt.plot(fpr, tpr, c='blue', label=f\"XGBoost-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "#plt.xlim([-0.1, 1.1])\n",
    "#plt.ylim([0, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/roc_compare_hifi.png\")\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f880120-a58e-4f9d-be3a-12b956551194",
   "metadata": {},
   "source": [
    "### Focus on 1% FPR with the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd000c1e-1d0b-4c1e-859f-798ecd708d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "#plt.axline([0,0], slope=1, c=\"black\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[:, 0], test_pred_cnn[:, 0], pos_label=1)\n",
    "\n",
    "idx_fpr = np.where(fpr <= 0.010)[0]\n",
    "\n",
    "thr_last = thresholds[idx_fpr][-1]\n",
    "\n",
    "print(f\"AUC-ROC CNN: {metrics.auc(fpr, tpr):.04f}\")\n",
    "plt.plot(fpr[idx_fpr], tpr[idx_fpr], c='gray', label=f\"CNN-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[:, 0], test_pred_xgb, pos_label=1)\n",
    "idx_fpr = np.where(fpr <= 0.010)[0]\n",
    "\n",
    "thr_last = thresholds[idx_fpr][-1]\n",
    "\n",
    "print(f\"AUC-ROC XGBoost: {metrics.auc(fpr, tpr):.04f}\")\n",
    "plt.plot(fpr[idx_fpr], tpr[idx_fpr], c='blue', label=f\"XGBoost-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "#plt.xlim([-0.1, 1.1])\n",
    "#plt.ylim([0, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/roc_compare_hifi_fdr_1.png\")\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3a81e-d891-4036-a091-13f175f7fc81",
   "metadata": {},
   "source": [
    "### Plot the PR curve using XGBoost and CNN predictions on HiFi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061439ec-6ba9-4a6f-9334-f9bbbc182172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.axline([0,0], slope=1, c=\"white\")\n",
    "plt.axline([0,1], slope=-1, c=\"black\")\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test[:, 0], test_pred_cnn[:, 0], pos_label=1)\n",
    "print(f\"AU-PR CNN: {metrics.average_precision_score(y_test[:, 0], test_pred_cnn[:, 0])}\")\n",
    "plt.plot(recall, precision, c='gray', label=f\"CNN-AUPR: {metrics.average_precision_score(y_test[:, 0], test_pred_cnn[:, 0]):.03f}\")\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_test[:, 0], test_pred_xgb, pos_label=1)\n",
    "print(f\"AU-PR XGBoost: {metrics.average_precision_score(y_test[:, 0], test_pred_xgb)}\")\n",
    "plt.plot(recall, precision, c='blue', label=f\"XGBoost-AUPR: {metrics.average_precision_score(y_test[:, 0], test_pred_xgb):.03f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"PR curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "#plt.xlim([0, 1])\n",
    "#plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/pr_compare_hifi.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90519dd9-0f46-42d4-887b-4067e75cffef",
   "metadata": {},
   "source": [
    "### Save model for RUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3fed8-bb44-474f-8aff-20382b24b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_PS00075.best.torch\", map_location=torch.device('cpu'))\n",
    "example = torch.rand(1, 6, 15)\n",
    "traced_script_module = torch.jit.trace(m6a_model, example)\n",
    "traced_script_module.save(\"models/m6ANet_PS00075.best.torch.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8be19-aeed-4451-83f7-369b8efe0490",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_other_half_hifi.3.best.torch\", map_location=torch.device('cpu'))\n",
    "example = torch.rand(1, 6, 15)\n",
    "traced_script_module = torch.jit.trace(m6a_model, example)\n",
    "traced_script_module.save(\"models/m6ANet_other_half_hifi.3.best.torch_nn.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e724b6-173e-4517-a79d-d22ca95d75d5",
   "metadata": {},
   "source": [
    "## Test on different data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91942abe-b225-426c-99f1-b465b7223132",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"/net/noble/vol4/noble/user/anupamaj/proj/m6A-calling/data/PS00075_2_2022-10-17.npz\"\n",
    "input_size = 6\n",
    "# Load validation data\n",
    "val_data = np.load(val_path, allow_pickle=True)\n",
    "X_val = val_data['features'][:, 0:input_size, :]\n",
    "y_val = val_data['labels']\n",
    "    \n",
    "y_val_ohe = np.zeros((len(y_val), 2))\n",
    "y_val_ohe[np.where(y_val == 1)[0], 0] = 1\n",
    "y_val_ohe[np.where(y_val == 0)[0], 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5bfc797-4f42-4249-8fa1-99ffc6dc436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 30, 11]             930\n",
      "            Conv1d-2                [-1, 10, 7]           1,510\n",
      "            Conv1d-3                 [-1, 5, 5]             155\n",
      "            Linear-4                    [-1, 5]             130\n",
      "            Linear-5                    [-1, 2]              12\n",
      "================================================================\n",
      "Total params: 2,737\n",
      "Trainable params: 2,737\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56081/153090769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mval_pred_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm6a_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/net/noble/vol4/noble/user/anupamaj/proj/m6A-calling/anupamaj/m6a_calling.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, batch_size, device)\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;31m# Run the data through the forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;31m# function to generate label predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0mm6a_labels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                 \u001b[0;31m# Move the label predictions to the CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mm6a_labels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm6a_labels_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/noble/vol4/noble/user/anupamaj/proj/m6A-calling/anupamaj/m6a_calling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \"\"\"\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# Three convolutional layers with ReLU activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    292\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 294\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    295\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_PS00075_no_init.3.best.torch\")\n",
    "#, map_location=torch.device('cpu')\n",
    "# Print model architecture summary\n",
    "summary_str = summary(m6a_model, input_size=(6, 15))\n",
    "\n",
    "X_val = torch.Tensor(X_val)\n",
    "val_pred_cnn = m6a_model.predict(X_val, device='cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a3416-3ab1-4816-8c5a-a1969096910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst2 = xgb.Booster({'nthread': 4})  # init model\n",
    "bst2.load_model('models/xgboost.otherhalf.hifi.100rds.json')  # load data\n",
    "\n",
    "X_val_2d = X_val.reshape(X_val.shape[0], X_val.shape[1] * X_val.shape[2])\n",
    "\n",
    "dval = xgb.DMatrix(X_val_2d)\n",
    "val_pred_xgb = bst2.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668aa8eb-ef98-404d-bb06-5d455dc1f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.axline([0,0], slope=1, c=\"black\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val_ohe[:, 0], val_pred_cnn[:, 0], pos_label=1)\n",
    "print(f\"AUC-ROC CNN: {metrics.auc(fpr, tpr):.03f}\")\n",
    "plt.plot(fpr, tpr, c='gray', label=f\"CNN-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "#plt.xlim([-0.1, 1.1])\n",
    "#plt.ylim([0, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/roc_compare_hifi_PS00075.png\")\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82e4f2-999f-4f48-b362-157e643035f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "#plt.axline([0,0], slope=1, c=\"black\")\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val_ohe[:, 0], val_pred_cnn[:, 0], pos_label=1)\n",
    "\n",
    "idx_fpr = np.where(fpr <= 0.050)[0]\n",
    "\n",
    "thr_last = thresholds[idx_fpr][-1]\n",
    "print(thresholds[idx_fpr])\n",
    "\n",
    "print(thr_last)\n",
    "\n",
    "print(f\"AUC-ROC CNN: {metrics.auc(fpr, tpr):.04f}\")\n",
    "plt.plot(fpr[idx_fpr], tpr[idx_fpr], c='gray', label=f\"CNN-AUROC: {metrics.auc(fpr, tpr):.04f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"ROC curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "#plt.xlim([-0.1, 1.1])\n",
    "#plt.ylim([0, 1.1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/roc_compare_hifi_fdr_1_PS00075.png\")\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4868d77-9ca5-4de5-870d-b5c89d2f5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.axline([0,0], slope=1, c=\"white\")\n",
    "plt.axline([0,1], slope=-1, c=\"black\")\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_val_ohe[:, 0], val_pred_cnn[:, 0], pos_label=1)\n",
    "print(f\"AU-PR CNN: {metrics.average_precision_score(y_val_ohe[:, 0], val_pred_cnn[:, 0])}\")\n",
    "plt.plot(recall, precision, c='gray', label=f\"CNN-AUPR: {metrics.average_precision_score(y_val_ohe[:, 0], val_pred_cnn[:, 0]):.03f}\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.title(\"PR curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "#plt.xlim([0, 1])\n",
    "#plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/pr_compare_hifi_PS00075.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc68de4-e5c5-4220-9a22-5077e8d0f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "#plt.axline([0,0], slope=1, c=\"white\")\n",
    "#plt.axline([0,1], slope=-1, c=\"black\")\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_val_ohe[:, 0], val_pred_cnn[:, 0], pos_label=1)\n",
    "print(len(precision), len(thresholds))\n",
    "print(f\"AU-PR CNN: {metrics.average_precision_score(y_val_ohe[:, 0], val_pred_cnn[:, 0])}\")\n",
    "plt.plot(thresholds, precision[1:], c='gray', label=f\"threshold vs precision\")\n",
    "plt.plot(thresholds, recall[1:], c='red', label=f\"threshold vs recall\")\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "#plt.title(\"threshold vs precision\")\n",
    "plt.xlabel(\"thresholds\")\n",
    "#plt.ylabel(\"Precision\")\n",
    "#plt.xlim([0, 1])\n",
    "#plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/pr_compare_hifi_PS00075.png\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da8385-ee2d-456b-9ed0-1f2ac4723960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974508c4-4cee-4eec-b89f-b84b867e7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_PS00075_no_init.3.best.torch\", map_location=torch.device('cpu'))\n",
    "example = torch.rand(1, 6, 15)\n",
    "traced_script_module = torch.jit.trace(m6a_model, example)\n",
    "traced_script_module.save(\"models/m6ANet_PS00075_no_init.3.best.torch.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6345790-c1af-47ff-ab5f-834cff815dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6a_model = torch.load(\"models/m6ANet_PS00075_semi_supervised.3.best.torch\", map_location=torch.device('cpu'))\n",
    "example = torch.rand(1, 6, 15)\n",
    "traced_script_module = torch.jit.trace(m6a_model, example)\n",
    "traced_script_module.save(\"models/m6ANet_PS00075_semi_supervised.3.best.torch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf121a-31e4-4247-b3af-ae87ae263e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02858e8d-c1ef-4480-9551-d6b21746a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
