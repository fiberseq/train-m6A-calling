{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03de45c8-221a-4d7b-80c3-7c9f97af4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
    "    \n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc16915-fb96-41f9-847b-43c95f03b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "def generate_random_data(n):\n",
    "    SOS_token = np.array([2])\n",
    "    EOS_token = np.array([3])\n",
    "    length = 8\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 0,0,0,0 -> 0,0,0,0\n",
    "    for i in range(n // 3):\n",
    "        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "        data.append([X, y])\n",
    "\n",
    "    # 1,0,1,0 -> 1,0,1,0,1\n",
    "    for i in range(n // 3):\n",
    "        X = np.zeros(length)\n",
    "        start = np.random.randint(0, 1)\n",
    "\n",
    "        X[start::2] = 1\n",
    "\n",
    "        y = np.zeros(length)\n",
    "        if X[-1] == 0:\n",
    "            y[::2] = 1\n",
    "        else:\n",
    "            y[1::2] = 1\n",
    "\n",
    "        X = np.concatenate((SOS_token, X, EOS_token))\n",
    "        y = np.concatenate((SOS_token, y, EOS_token))\n",
    "\n",
    "        data.append([X, y])\n",
    "\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            # Here you would need to get the max length of the batch,\n",
    "            # and normalize the length with the PAD token.\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "\n",
    "                # Get longest sentence in batch\n",
    "                for seq in data[idx : idx + batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "\n",
    "                # Append X padding tokens until it reaches the max length\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
    "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
    "\n",
    "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_data = generate_random_data(9000)\n",
    "val_data = generate_random_data(3000)\n",
    "\n",
    "train_dataloader = batchify_data(train_data)\n",
    "val_dataloader = batchify_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bec2b7-4599-4fa1-92a7-3c5a824bd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20adcba0-0c7e-4c22-87a4-5f2ad2dbaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "        \n",
    "        print(f\"X: {X}\")\n",
    "        print(f\"y: {y}\")\n",
    "        \n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "        \n",
    "        print(f\"tgt_mask: {tgt_mask}\")\n",
    "        \n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "        \n",
    "        print(pred)\n",
    "        \n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y_expected)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        break\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e285c82f-9e08-4ffb-bf78-2bc3423657ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35975926833432764"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop(model, opt, loss_fn, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55c963a0-e612-4547-bec1-51440c6cf715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3]])\n",
      "y: tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
      "        [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n",
      "        [2, 1, 0, 1, 0, 1, 0, 1, 0, 3]])\n",
      "tgt_mask: tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[[-2.6392,  2.8567, -1.7862,  0.5057],\n",
      "         [-2.9245,  3.0610, -1.3120,  0.7274],\n",
      "         [-1.6993,  2.0760, -2.4109,  0.1395],\n",
      "         [-2.5573,  2.9323, -1.7004,  0.2883],\n",
      "         [-2.1080,  3.0389, -1.3145, -0.4384],\n",
      "         [ 2.7761, -2.6148, -1.6380,  0.1952],\n",
      "         [-2.6418,  2.8273, -1.7213,  0.7077],\n",
      "         [-2.7044,  2.9853, -1.7348,  0.4420],\n",
      "         [-2.6979,  2.9074, -1.3822,  0.8632],\n",
      "         [ 3.0061, -2.5471, -1.8016, -0.4058],\n",
      "         [-2.5594,  3.1732, -1.5917, -0.0717],\n",
      "         [-2.0598,  2.7703, -2.0831, -0.1598],\n",
      "         [ 2.9403, -2.6126, -1.8368, -0.3116],\n",
      "         [-2.7731,  2.9536, -1.6338,  0.6432],\n",
      "         [ 2.9211, -2.1659, -1.5946, -0.6195],\n",
      "         [-2.0568,  2.8876, -1.9857, -0.4508]],\n",
      "\n",
      "        [[-2.8838,  2.9259, -1.4218,  0.9012],\n",
      "         [-2.9428,  3.0727, -1.1369,  0.8583],\n",
      "         [ 2.9887, -2.6181, -1.8160, -0.3633],\n",
      "         [-2.6718,  2.8581, -1.6228,  0.7419],\n",
      "         [ 3.3084, -2.5485, -0.6791, -0.6575],\n",
      "         [ 2.9094, -2.9212, -1.1885,  0.4700],\n",
      "         [-2.9159,  3.1173, -1.2608,  0.7433],\n",
      "         [-0.7140,  1.7938, -0.8579, -0.4059],\n",
      "         [-2.9057,  2.9689, -1.3306,  0.8589],\n",
      "         [ 2.5385, -2.3568, -1.8230,  0.1152],\n",
      "         [ 3.1988, -2.2649, -1.2905, -0.9688],\n",
      "         [ 3.2155, -2.8405, -1.3345, -0.1481],\n",
      "         [ 2.1553, -2.1429, -2.0940,  0.3069],\n",
      "         [-2.9434,  2.9784, -1.2991,  0.8801],\n",
      "         [ 2.4626, -2.4629, -1.7521,  0.4504],\n",
      "         [ 3.0715, -2.5636, -1.5589, -0.5135]],\n",
      "\n",
      "        [[-2.5028,  3.0153, -1.4626, -0.0173],\n",
      "         [-2.6354,  2.9129, -1.5440,  0.4763],\n",
      "         [-2.6022,  2.4906, -1.7813,  0.8157],\n",
      "         [-2.7305,  3.0101, -1.4731,  0.6620],\n",
      "         [-2.5562,  2.3977, -1.7300,  0.6956],\n",
      "         [ 2.7798, -2.7400, -1.6176,  0.2595],\n",
      "         [-2.8944,  3.0197, -1.2619,  0.8078],\n",
      "         [-2.8917,  2.8443, -1.0928,  1.0708],\n",
      "         [-2.9415,  3.0501, -1.2175,  0.7720],\n",
      "         [ 2.5004, -2.5487, -1.5380,  0.4571],\n",
      "         [-2.7067,  2.5357, -1.6032,  1.0444],\n",
      "         [-2.6734,  2.4729, -1.6049,  0.8782],\n",
      "         [ 2.6692, -2.4483, -1.7298,  0.0164],\n",
      "         [-2.8760,  2.9772, -1.4329,  0.7677],\n",
      "         [ 2.6648, -2.6376, -1.5427,  0.3831],\n",
      "         [-2.4305,  2.3305, -1.9319,  0.9327]],\n",
      "\n",
      "        [[-2.7811,  2.8557, -1.6202,  0.7898],\n",
      "         [-2.8681,  2.8998, -1.1871,  0.8570],\n",
      "         [ 2.7488, -1.9053, -1.1930, -1.1338],\n",
      "         [-2.5803,  2.7376, -1.7618,  0.4918],\n",
      "         [ 3.2185, -2.6333, -1.0429, -0.4361],\n",
      "         [ 2.9628, -2.9138, -1.1943,  0.2640],\n",
      "         [-2.7025,  2.7941, -1.1981,  1.0850],\n",
      "         [-2.7048,  2.8498, -1.4798,  0.6205],\n",
      "         [-2.8846,  3.0894, -1.4033,  0.6353],\n",
      "         [ 2.4762, -2.5132, -1.7107,  0.3303],\n",
      "         [ 3.1677, -2.3640, -1.4139, -1.0789],\n",
      "         [ 3.2925, -2.7245, -1.0632, -0.3032],\n",
      "         [ 2.3553, -2.5499, -1.6327,  0.5236],\n",
      "         [-2.7390,  2.9708, -1.1525,  0.8591],\n",
      "         [ 2.2588, -2.2648, -1.8941,  0.4603],\n",
      "         [ 2.8984, -1.9187, -1.8113, -1.2733]],\n",
      "\n",
      "        [[-2.8203,  3.1289, -1.5081,  0.4373],\n",
      "         [-2.5780,  2.8438, -1.5717,  0.3052],\n",
      "         [-1.9276,  1.5910, -2.0959,  1.0434],\n",
      "         [-2.6758,  3.0337, -1.5971,  0.4246],\n",
      "         [-2.4828,  2.1369, -1.6254,  1.2889],\n",
      "         [ 2.9233, -2.7616, -1.1976,  0.1173],\n",
      "         [-2.8570,  2.8993, -1.3501,  0.9891],\n",
      "         [-2.7035,  3.0839, -1.2450,  0.5691],\n",
      "         [-2.4493,  2.9434, -1.3608,  0.3579],\n",
      "         [ 2.4512, -2.5722, -1.5823,  0.6216],\n",
      "         [-2.6035,  2.3475, -1.5544,  1.2843],\n",
      "         [-2.5499,  2.1053, -1.3912,  1.5247],\n",
      "         [ 2.6929, -2.7089, -1.4612,  0.4216],\n",
      "         [-2.7516,  2.9793, -1.3597,  0.7571],\n",
      "         [ 2.6834, -2.7953, -1.3391,  0.5129],\n",
      "         [-2.4546,  2.3011, -1.9098,  0.9383]],\n",
      "\n",
      "        [[-2.6889,  3.0226, -0.8438,  0.8435],\n",
      "         [-2.8307,  2.8398, -1.4242,  0.9484],\n",
      "         [ 2.8611, -2.1497, -1.7281, -0.4525],\n",
      "         [-2.8200,  2.9914, -1.3791,  0.8015],\n",
      "         [ 3.2614, -2.6416, -1.5220, -0.6657],\n",
      "         [ 2.5002, -2.4722, -1.7611,  0.1965],\n",
      "         [-2.8730,  3.0313, -1.3300,  0.8004],\n",
      "         [-2.9409,  3.0115, -1.0783,  0.8235],\n",
      "         [-2.7322,  2.9662, -1.6218,  0.6187],\n",
      "         [ 2.3666, -2.3074, -1.7961,  0.1923],\n",
      "         [ 2.6451, -1.3119, -1.1765, -1.4695],\n",
      "         [ 3.2501, -2.5263, -1.3800, -0.6661],\n",
      "         [ 2.5544, -2.6220, -1.6197,  0.4166],\n",
      "         [-2.9728,  3.0454, -0.9281,  0.7341],\n",
      "         [ 2.2377, -2.2099, -1.6403,  0.4360],\n",
      "         [ 3.0561, -2.1998, -1.8076, -1.1032]],\n",
      "\n",
      "        [[-2.6311,  3.1562, -0.9774,  0.5153],\n",
      "         [-2.9052,  3.0430, -1.1713,  0.8169],\n",
      "         [-2.4867,  2.2958, -1.8214,  1.0131],\n",
      "         [-2.9944,  3.2599, -1.1307,  0.4976],\n",
      "         [-2.4079,  2.1266, -1.5810,  1.0073],\n",
      "         [ 2.5388, -2.5085, -1.5611,  0.2452],\n",
      "         [-2.7972,  2.9188, -1.5179,  0.8046],\n",
      "         [-2.2915,  2.9091, -1.6194,  0.1561],\n",
      "         [-2.5462,  2.9069, -1.6071,  0.2815],\n",
      "         [ 1.7989, -2.1835, -1.1549,  0.8751],\n",
      "         [-2.3262,  2.0016, -1.6921,  1.2690],\n",
      "         [-2.4909,  2.1019, -1.4311,  1.4895],\n",
      "         [ 2.7205, -2.7723, -1.3834,  0.3950],\n",
      "         [-2.7924,  2.9045, -1.6128,  0.6502],\n",
      "         [ 2.4220, -2.4974, -1.6157,  0.5435],\n",
      "         [-2.4478,  2.3821, -1.9456,  0.5906]],\n",
      "\n",
      "        [[-2.8836,  2.9666, -1.4371,  0.8129],\n",
      "         [-2.8153,  3.1369, -1.4874,  0.1035],\n",
      "         [ 2.8385, -2.1600, -1.5679, -1.0773],\n",
      "         [-2.8334,  3.0024, -1.3555,  0.6668],\n",
      "         [-0.4747,  0.7577, -2.4514,  0.0853],\n",
      "         [ 2.6935, -2.7413, -1.4287,  0.4630],\n",
      "         [-2.6540,  2.9684, -1.6260,  0.3696],\n",
      "         [-2.7298,  2.7038, -1.3232,  1.1711],\n",
      "         [-2.7374,  2.8532, -1.6988,  0.5884],\n",
      "         [ 2.3445, -2.4570, -1.6537,  0.4390],\n",
      "         [ 2.8817, -2.4503, -1.7026, -0.7347],\n",
      "         [ 3.2910, -2.7411, -1.3481, -0.3994],\n",
      "         [ 2.5005, -2.6367, -1.2387,  0.4730],\n",
      "         [-2.8196,  2.9970, -1.4716,  0.6837],\n",
      "         [ 2.4415, -2.6536, -1.3605,  0.7591],\n",
      "         [ 3.2739, -2.6530, -1.4757, -0.5848]],\n",
      "\n",
      "        [[-2.7602,  2.9873, -1.6232,  0.5876],\n",
      "         [-2.9077,  2.9337, -1.3905,  0.8592],\n",
      "         [-2.4751,  2.1113, -1.5868,  1.4413],\n",
      "         [-2.8127,  3.0039, -1.4882,  0.7068],\n",
      "         [-2.5586,  2.2632, -1.5867,  1.2687],\n",
      "         [ 2.7787, -2.6349, -1.5032,  0.1362],\n",
      "         [-3.0144,  3.1477, -0.7712,  0.8743],\n",
      "         [-2.3471,  2.7662, -1.6834,  0.0862],\n",
      "         [-2.5946,  2.6808, -0.8461,  0.7675],\n",
      "         [ 2.2912, -2.3978, -1.7668,  0.4804],\n",
      "         [-2.1718,  1.7978, -1.8166,  1.1513],\n",
      "         [-2.3149,  1.9890, -1.6392,  1.0283],\n",
      "         [ 2.4579, -2.5903, -1.3141,  0.5343],\n",
      "         [-2.8411,  3.0072, -1.2234,  0.7975],\n",
      "         [ 2.5311, -2.6211, -1.5231,  0.5289],\n",
      "         [-2.4840,  2.3502, -1.6982,  1.2262]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000618938767613041"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loop(model, opt, loss_fn, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca4615-0938-4eed-8287-190104fa534c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
